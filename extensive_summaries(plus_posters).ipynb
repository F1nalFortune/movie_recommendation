{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "from functools import wraps\n",
    "from colorama import Fore\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "from requests import ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianphelps/opt/anaconda3/envs/thesis/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil\n",
    "from datetime import timedelta\n",
    "from IPython.core.display import clear_output\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "tqdm.pandas()\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=20, delay=3, backoff=2, logger=None):\n",
    "    \"\"\"Retry calling the decorated function using an exponential backoff.\n",
    "\n",
    "    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n",
    "    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "    \n",
    "    :param ExceptionToCheck: the exception to check. may be a tuple of\n",
    "        exceptions to check\n",
    "    :type ExceptionToCheck: Exception or tuple\n",
    "    :param tries: number of times to try (not retry) before giving up\n",
    "    :type tries: int\n",
    "    :param delay: initial delay between retries in seconds\n",
    "    :type delay: int\n",
    "    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n",
    "        each retry\n",
    "    :type backoff: int\n",
    "    :param logger: logger to use. If None, print\n",
    "    :type logger: logging.Logger instance\n",
    "    \"\"\"\n",
    "    def deco_retry(f):\n",
    "\n",
    "        @wraps(f)\n",
    "        def f_retry(*args, **kwargs):\n",
    "            mtries, mdelay = tries, delay\n",
    "            while mtries > 1:\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                except ExceptionToCheck:\n",
    "                    msg = \"%s, Retrying in %d seconds...\" % (str(ExceptionToCheck), mdelay)\n",
    "                    if logger:\n",
    "                        #logger.exception(msg) # would print stack trace\n",
    "                        logger.warning(msg)\n",
    "                    else:\n",
    "                        print(msg)\n",
    "                    time.sleep(mdelay)\n",
    "                    mtries -= 1\n",
    "                    mdelay *= backoff\n",
    "            return f(*args, **kwargs)\n",
    "\n",
    "        return f_retry  # true decorator\n",
    "\n",
    "    return deco_retry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"no-sandbox\")\n",
    "options.add_argument(\"disable-dev-shm-usage\")\n",
    "options.add_argument(\"headless\")\n",
    "options.add_argument(\"user-data-dir=/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_Swoops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in lists\n",
    "def scrapeMovies(data, saved_data=False):\n",
    "  #for every page\n",
    "  count=0\n",
    "  if type(saved_data)!=bool:\n",
    "    add_feats = saved_data\n",
    "    data = data.iloc[len(add_feats):]\n",
    "  else:\n",
    "    add_feats = pd.DataFrame()\n",
    "  for row in data.itertuples():\n",
    "    name = row.name\n",
    "    year = row.year\n",
    "    profile = row.profile\n",
    "    count+=1\n",
    "\n",
    "    link = f\"https://www.imdb.com{profile}\"\n",
    "    \n",
    "    @retry((ConnectionResetError, ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2,backoff=2)\n",
    "    def get_response():\n",
    "      response = get(link)\n",
    "      return response\n",
    "    response = get_response()\n",
    "\n",
    "    # parse the content of request\n",
    "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    print(Fore.GREEN + f\"{name}({count})\\n\")\n",
    "\n",
    "    '''\n",
    "      GRAB PLOT SYNOPSIS\n",
    "    '''\n",
    "    synopsis_link = profile\n",
    "    @retry((ConnectionResetError, ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "    def get_synopsis():\n",
    "      synopsis = get(\"https://www.imdb.com/\" + synopsis_link + \"plotsummary\")\n",
    "      return synopsis\n",
    "    synopsis = get_synopsis()\n",
    "    synopsis_html = BeautifulSoup(synopsis.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "      plot_synopsis_content = synopsis_html.find(\"ul\", {\"id\": \"plot-synopsis-content\"}).li.text\n",
    "      plot_synopsis_content = plot_synopsis_content.strip()\n",
    "      if plot_synopsis_content[:58] != \"It looks like we don't have a Synopsis for this title yet.\":\n",
    "        print(Fore.GREEN + 'Plot Synopsis\\n')\n",
    "      else:\n",
    "        plot_synopsis_content = np.nan\n",
    "        print(Fore.RED + 'Plot Synopsis\\n')\n",
    "    except:\n",
    "      plot_synopsis_content = np.nan\n",
    "      print(Fore.RED + 'Plot Synopsis\\n')\n",
    "    '''\n",
    "        GRAB SUMMARIES\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "      summary_bucket = []\n",
    "      summaries = synopsis_html.find('ul', attrs={\"id\":\"plot-summaries-content\"}).find_all('li')\n",
    "      for summary in summaries:\n",
    "        result = summary.p.text.strip()\n",
    "        summary_bucket.append(result)\n",
    "      summaries = summary_bucket\n",
    "      print(Fore.GREEN + f'Summaries: {len(summary_bucket)}\\n')\n",
    "    except:\n",
    "      summaries = np.nan\n",
    "      print(Fore.RED + 'Summary\\n')\n",
    "\n",
    "   \n",
    "    '''\n",
    "      MOVIE POSTER\n",
    "    '''\n",
    "    driver = webdriver.Chrome(\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=options)\n",
    "    try:\n",
    "      image_url = f\"https://www.imdb.com/{page_html.find('div', class_='poster').a['href']}\"\n",
    "      @retry((ConnectionResetError, ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2,backoff=2)\n",
    "      def get_response(link):\n",
    "        driver.get(link)\n",
    "      get_response(image_url)\n",
    "      poster_html = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "      \n",
    "      try:\n",
    "        image_url = poster_html.find_all('div', class_='pswp__item')[1].find('img', class_='pswp__img')['src']\n",
    "      except:\n",
    "        image_url = poster_html.find_all('img')[1]['src']\n",
    "      \n",
    "      movie_name = name.replace(\" \", \"_\")\n",
    "      \n",
    "      img = Image.open(requests.get(image_url, stream = True).raw)\n",
    "      try:\n",
    "        img.save(f'./posters/{movie_name}_{year}.jpg')\n",
    "      except:\n",
    "        img.convert('RGB').save(f'./posters/{movie_name}_{year}.jpg')\n",
    "        \n",
    "      poster = f\"./posters/{movie_name}_{year}.jpg\"\n",
    "      print(Fore.GREEN + 'Poster\\n')\n",
    "    except Exception as e:\n",
    "      poster = np.nan\n",
    "      print(e)\n",
    "      print(Fore.RED + 'Poster\\n')\n",
    "      \n",
    "    driver.quit()\n",
    "    movie = pd.DataFrame({\n",
    "      'name': [name],\n",
    "      'profile': [profile],\n",
    "      'synopsis': [plot_synopsis_content],\n",
    "      'summaries': [summaries],\n",
    "      'poster': [poster]\n",
    "    })\n",
    "    add_feats = add_feats.append(movie, ignore_index=True)\n",
    "    add_feats.to_csv(f\"./add_feats.csv\", index=False)\n",
    "    print(f\"Movies:  {len(add_feats)}\\n\")\n",
    "    clear_output(wait = True)\n",
    "  return add_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mMissionary(10653)\n",
      "\n",
      "\u001b[31mPlot Synopsis\n",
      "\n",
      "\u001b[32mSummaries: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = scrapeMovies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

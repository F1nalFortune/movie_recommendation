{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import ast\n",
    "import re\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "tqdm.pandas()\n",
    "import missingno as msno\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/brianphelps/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk.data\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "import torch\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  GRAB MOVIE DATA FROM THREADS\n",
    "'''\n",
    "def createDate(row):\n",
    "  if type(row)==str:\n",
    "    return dateutil.parser.parse(row).strftime('%Y-%m-%d')\n",
    "  else:\n",
    "    return np.nan\n",
    "\n",
    "def createDf():\n",
    "  path = \"./data//full_\"\n",
    "  paths = ['one', 'two', 'three', 'four', 'five', 'six']\n",
    "  df = pd.DataFrame()\n",
    "  for val in paths:\n",
    "    df = df.append(pd.read_csv(f\"{path}{val}.csv\"))\n",
    "  return df\n",
    "\n",
    "df = createDf()\n",
    "\n",
    "#DROP INVALID DISTRIBUTOR COLUMNS\n",
    "df = df.drop(columns=['distributor'])\n",
    "\n",
    "#DROP MOVIES WITHOUT DEPENDENT VARIABLE DATA\n",
    "# df.dropna(subset=['box_office'], inplace=True)\n",
    "\n",
    "#DROP DUPLICATE MOVIES\n",
    "df = df.drop_duplicates(subset=['profile'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=['cast_members','cast_anchors','directors','release','mpaa','stars','languages','prod_anchors','budget','box_office', 'int_office', 'runtime','director_credits','cinematographer','cin_anch','musician','musician_anchor', 'prod_designer', 'prod_designer_anchor','costume_designer','costume_designer_anchor','sequel','screen_writers','screen_anchors','screen_credits','spec_eff','sound_mix','producers','prod_credits','cast_count','comp_count','version_count','references_count']\n",
    "df=df.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['The plot is unknown at this time.','Add a Plot\\xa0»','Plot unknown.','Plot kept under wraps.','Plot is unknown.','The plot is unknown.','Plot is unknown at this time.','The plot is currently unknown.','Plot is being kept under wraps.']\n",
    "replace = ['See full summary\\xa0»','...\\n','\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True)\n",
    "error_count=0\n",
    "keep_indices=[]\n",
    "for idx,row in tqdm(enumerate(df.itertuples()),total=len(df)):\n",
    "  if row.summary in errors:\n",
    "    error_count+=1\n",
    "  else:\n",
    "    keep_indices.append(idx)\n",
    "  if type(row.summary)==str:\n",
    "    for val in replace:\n",
    "      if val in row.summary:\n",
    "        df.at[idx, 'summary']=row.summary.replace(val, \"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainProd(row):\n",
    "  try:\n",
    "    return row[0]\n",
    "  except:\n",
    "    return np.nan\n",
    "tqdm.pandas(desc=\"Production Company\")\n",
    "df['main_prod'] = df['pro_comp'].progress_apply(lambda x: ast.literal_eval(x)[0] if type(x)==str else np.nan)\n",
    "df=df.drop('pro_comp',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = ['sequels','director_anchors','star_anchs']\n",
    "for val in lists:\n",
    "  df[val]=df[val].apply(lambda x: ast.literal_eval(x) if type(x)==str else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_plots = []\n",
    "for idx, row in enumerate(df.itertuples()):\n",
    "  if type(row.summary)!=str:\n",
    "    if type(row.plot)==str:\n",
    "      df.at[idx, 'summary']=row.plot\n",
    "      fixed_plots.append(row.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fixed {len(fixed_plots)} movie summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['summary'])\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre and Director\n",
    "#### Genre and Stars\n",
    "#### Stars and Director\n",
    "#### Stars Director Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_len(text):\n",
    "  result = len(tokenizer.tokenize(text))\n",
    "  return result\n",
    "df['summary_len']=df['summary'].apply(summary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['summary_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count']=df['summary'].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['word_count']<25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['word_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(df['summary_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "  preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "  t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "\n",
    "  tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "  # summmarize \n",
    "  summary_ids = model.generate(tokenized_text,\n",
    "                                      num_beams=4,\n",
    "                                      no_repeat_ngram_size=2,\n",
    "                                      max_length=30,\n",
    "                                      early_stopping=True)\n",
    "\n",
    "  output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_input'] = df['summary'].parallel_apply(summarize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_input']=values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-small were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text preprocessed: \n",
      " The US has \"passed the peak\" on new coronavirus cases, President Donald Trump said and predicted that some states would reopen this month.The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.At the daily White House coronavirus briefing on Wednesday, Trump said new guidelines to reopen the country would be announced on Thursday after he speaks to governors.\"We'll be the comeback kids, all of us,\" he said. \"We want to get our country back.\"The Trump administration has previously fixed May 1 as a possible date to reopen the world's largest economy, but the president said some states may be able to return to normalcy earlier than that.\n",
      "\n",
      "\n",
      "Summarized text: \n",
      " the president predicts some states will reopen this month. the u.s. has over 637,000 confirmed cases and over 30,826 deaths, the highest for any country in the world. \"we want to get our country back,\" he says.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "\n",
    "text =\"\"\"\n",
    "The US has \"passed the peak\" on new coronavirus cases, President Donald Trump said and predicted that some states would reopen this month.\n",
    "The US has over 637,000 confirmed Covid-19 cases and over 30,826 deaths, the highest for any country in the world.\n",
    "At the daily White House coronavirus briefing on Wednesday, Trump said new guidelines to reopen the country would be announced on Thursday after he speaks to governors.\n",
    "\"We'll be the comeback kids, all of us,\" he said. \"We want to get our country back.\"\n",
    "The Trump administration has previously fixed May 1 as a possible date to reopen the world's largest economy, but the president said some states may be able to return to normalcy earlier than that.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "print (\"original text preprocessed: \\n\", preprocess_text)\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer(\n",
    "    transformer_type= 'Albert',\n",
    "    transformer_model_key= 'albert-base-v2'    \n",
    ")\n",
    "def summarize_review(row):\n",
    "  result = len(tokenizer.tokenize(row))\n",
    "  if result>3:\n",
    "    return model(row,num_sentences=3)\n",
    "  else:\n",
    "    return row\n",
    "\n",
    "df['summarized_summary'] = df['summary'].progress_apply(summarize_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three decades after the Empire's defeat, a new threat arises in the militant First Order.\n",
      "-----\n",
      "Defected stormtrooper Finn and the scavenger Rey are caught up in the Resistance's search for the missing Luke Skywalker.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = df['summary'][0]\n",
    "\n",
    "\n",
    "\n",
    "print('\\n-----\\n'.join(tokenizer.tokenize(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df['bag_of_words'])\n",
    "\n",
    "# generating the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "import random\n",
    "import chart_studio.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "pd.options.display.max_columns = 30\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='solar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>274307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>162936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>160812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>149960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plot</td>\n",
       "      <td>148316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>add</td>\n",
       "      <td>146886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>122313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>91328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>his</td>\n",
       "      <td>88662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>see</td>\n",
       "      <td>73759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>full</td>\n",
       "      <td>73634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>summary</td>\n",
       "      <td>70821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>with</td>\n",
       "      <td>54139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>her</td>\n",
       "      <td>53294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>he</td>\n",
       "      <td>48986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>an</td>\n",
       "      <td>46192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for</td>\n",
       "      <td>40060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>who</td>\n",
       "      <td>38596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>on</td>\n",
       "      <td>37509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>by</td>\n",
       "      <td>37310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc   count\n",
       "0       the  274307\n",
       "1        to  162936\n",
       "2        of  160812\n",
       "3       and  149960\n",
       "4      plot  148316\n",
       "5       add  146886\n",
       "6        in  122313\n",
       "7        is   91328\n",
       "8       his   88662\n",
       "9       see   73759\n",
       "10     full   73634\n",
       "11  summary   70821\n",
       "12     with   54139\n",
       "13      her   53294\n",
       "14       he   48986\n",
       "15       an   46192\n",
       "16      for   40060\n",
       "17      who   38596\n",
       "18       on   37509\n",
       "19       by   37310"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "  vec = CountVectorizer().fit(corpus)\n",
    "  bag_of_words = vec.transform(corpus)\n",
    "  sum_words = bag_of_words.sum(axis=0) \n",
    "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "  return words_freq[:n]\n",
    "common_words = get_top_n_words(df['summary'].dropna(), 20)\n",
    "df1 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot</td>\n",
       "      <td>148316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add</td>\n",
       "      <td>146886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary</td>\n",
       "      <td>70821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>young</td>\n",
       "      <td>24506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life</td>\n",
       "      <td>20672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>19702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>love</td>\n",
       "      <td>17078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>story</td>\n",
       "      <td>14746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>woman</td>\n",
       "      <td>13348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>family</td>\n",
       "      <td>12738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>film</td>\n",
       "      <td>12489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new</td>\n",
       "      <td>11207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>girl</td>\n",
       "      <td>11136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>old</td>\n",
       "      <td>10733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>father</td>\n",
       "      <td>10344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>world</td>\n",
       "      <td>9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wife</td>\n",
       "      <td>8962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>friends</td>\n",
       "      <td>8280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lives</td>\n",
       "      <td>8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>years</td>\n",
       "      <td>7933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       desc   count\n",
       "0      plot  148316\n",
       "1       add  146886\n",
       "2   summary   70821\n",
       "3     young   24506\n",
       "4      life   20672\n",
       "5       man   19702\n",
       "6      love   17078\n",
       "7     story   14746\n",
       "8     woman   13348\n",
       "9    family   12738\n",
       "10     film   12489\n",
       "11      new   11207\n",
       "12     girl   11136\n",
       "13      old   10733\n",
       "14   father   10344\n",
       "15    world    9022\n",
       "16     wife    8962\n",
       "17  friends    8280\n",
       "18    lives    8204\n",
       "19    years    7933"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "  vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "  bag_of_words = vec.transform(corpus)\n",
    "  sum_words = bag_of_words.sum(axis=0) \n",
    "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "  return words_freq[:n]\n",
    "common_words = get_top_n_words(df['summary'].dropna(), 20)\n",
    "df2 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a20488c24b42709a5d885b89753608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brian\\anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  CONVERT COLUMNS TO LISTS\n",
    "'''\n",
    "import ast\n",
    "\n",
    "def cleanColumn(row):\n",
    "  try:\n",
    "    if type(row)==str:\n",
    "      values = ast.literal_eval(row)\n",
    "      if type(values)!=dict:\n",
    "        cleaned_values=[]\n",
    "        for val in values:\n",
    "          val = val.replace(\",\", \"\").strip()\n",
    "          cleaned_values.append(val)\n",
    "        return cleaned_values\n",
    "      else:\n",
    "        return values\n",
    "    else:\n",
    "      return np.nan\n",
    "  except:\n",
    "    return np.nan\n",
    "\n",
    "columns = ['sequel',\n",
    "'cast_members',\n",
    "'cast_anchors',\n",
    "'directors',\n",
    "'director_anchors',\n",
    "'director_credits',\n",
    "'pro_comp',\n",
    "'spec_eff',\n",
    "'sound_mix',\n",
    "'stars',\n",
    "'star_anchs',\n",
    "'screen_writers',\n",
    "'screen_anchors',\n",
    "'screen_credits',\n",
    "'producers',\n",
    "'prod_anchors',\n",
    "'prod_credits',\n",
    "'genre',\n",
    "'comp_count',\n",
    "'cast_count']\n",
    "\n",
    "for value in tqdm(columns):\n",
    "  tqdm.pandas(desc=\"Creating Datetime\")\n",
    "  df[value] = df[value].apply(cleanColumn)\n",
    "\n",
    "df['cast'] = df['cast_members']\n",
    "df = df.drop(columns=['cast_members', 'sequels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee07b081914326a5c32c2d25e6173a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Creating Date', max=367803, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82e3d3df9c84381b2e96d8a219ae740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Creating Datetime', max=271994, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b05490e8cb4ca690c8b22a9afd47eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Creating Year Column', max=271994, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c65b41071fb4c8da74cc322c76764a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Creating Month Column', max=271994, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  CONVERT DATE INTO ISO FORMAT\n",
    "'''\n",
    "def createDates(row):\n",
    "  if type(row)==str:\n",
    "    return dateutil.parser.parse(row).strftime('%Y-%m-%d')\n",
    "  else:\n",
    "    return np.nan\n",
    "\n",
    "def createDateTime(row):\n",
    "  row = row.split(\"-\")\n",
    "  row = datetime.datetime(int(row[0]), int(row[1]), int(row[2]))\n",
    "  return row\n",
    "\n",
    "tqdm.pandas(desc=\"Creating Date\")\n",
    "df['date'] = df['release'].progress_apply(createDates)\n",
    "df = df.dropna(subset=['date'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "tqdm.pandas(desc=\"Creating Datetime\")\n",
    "df['datetime'] = df['date'].progress_apply(createDateTime)\n",
    "tqdm.pandas(desc=\"Creating Year Column\")\n",
    "df['year'] = df['datetime'].progress_apply(lambda x: x.year)\n",
    "tqdm.pandas(desc=\"Creating Month Column\")\n",
    "df['month'] = df['datetime'].progress_apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead28924fd5f4cb5b0070f07e9bf4e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Production Company', max=271994, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "feature_engineering.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:recommender] *",
   "language": "python",
   "name": "conda-env-recommender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
